{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6MD4dXx/nUW5BQ5KfKnSl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makaryb/nn2s5k/blob/master/lab2/src/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLei-pFXgze-",
        "colab_type": "code",
        "outputId": "58f054e0-b47d-4c48-d2b9-46b2df24593c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# get acess google drive data into google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mksxa8WwijFx",
        "colab_type": "code",
        "outputId": "b4ca9652-5137-4959-cf84-181820e2c0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "filename = \"/content/data7/dataset.zip\"\n",
        "with ZipFile(filename, \"r\") as zip:\n",
        "  zip.extractall()\n",
        "  print(\"finish\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s370AkNIjB08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xe-d_csjMYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "# initializing the CNN\n",
        "CNN_Classifier = Sequential();\n",
        "\n",
        "# convolution\n",
        "CNN_Classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "\n",
        "# pooling\n",
        "CNN_Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# convolution\n",
        "CNN_Classifier.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "\n",
        "# pooling\n",
        "CNN_Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# flattening\n",
        "CNN_Classifier.add(Flatten())\n",
        "\n",
        "# full connection\n",
        "CNN_Classifier.add(Dense(units=128, activation='relu'))\n",
        "CNN_Classifier.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# compiling the CNN\n",
        "CNN_Classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBdqAFCsmQqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "6be793ff-89ea-4537-c75b-e6d6ae2b7a3d"
      },
      "source": [
        "# fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "CNN_Classifier.fit_generator(training_set, \n",
        "                             steps_per_epoch = 7000,\n",
        "                             epochs = 10,\n",
        "                             validation_data = test_set,\n",
        "                             validation_steps = 2000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20002 images belonging to 2 classes.\n",
            "Found 4998 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7000/7000 [==============================] - 1825s 261ms/step - loss: 0.4581 - acc: 0.7777 - val_loss: 0.4558 - val_acc: 0.7968\n",
            "Epoch 2/10\n",
            "7000/7000 [==============================] - 1822s 260ms/step - loss: 0.3010 - acc: 0.8706 - val_loss: 0.4790 - val_acc: 0.8231\n",
            "Epoch 3/10\n",
            "7000/7000 [==============================] - 1835s 262ms/step - loss: 0.2104 - acc: 0.9135 - val_loss: 0.5770 - val_acc: 0.8202\n",
            "Epoch 4/10\n",
            "7000/7000 [==============================] - 1823s 260ms/step - loss: 0.1534 - acc: 0.9393 - val_loss: 0.6576 - val_acc: 0.8079\n",
            "Epoch 5/10\n",
            " 104/7000 [..............................] - ETA: 24:58 - loss: 0.1355 - acc: 0.9450"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snc69UDhoSer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction for cat/dog image using train model\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = CNN_Classifier.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "  print(prediction)\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "  print(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}