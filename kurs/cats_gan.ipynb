{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhbL+he9f3CtUyL3zekCrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makaryb/nn2s5k/blob/master/kurs/cats_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htI4PY14vB7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLei-pFXgze-",
        "colab_type": "code",
        "outputId": "58f054e0-b47d-4c48-d2b9-46b2df24593c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# get acess google drive data into google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ7QORw4vEz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mksxa8WwijFx",
        "colab_type": "code",
        "outputId": "b4ca9652-5137-4959-cf84-181820e2c0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "filename = \"/content/data7/dataset.zip\"\n",
        "with ZipFile(filename, \"r\") as zip:\n",
        "  zip.extractall()\n",
        "  print(\"finish\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cwyhQchvU7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd6d2ed1-6b3a-407c-a364-3beaafbaccb1"
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras.layers import Activation, Dense, Conv2D, UpSampling2D, LeakyReLU, Reshape, Flatten, Input, BatchNormalization, Dropout"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64C8trnmvc30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(img_shape):\n",
        "    model = Sequential()  # 64x64\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=5, strides=2, input_shape=img_shape, padding=\"same\"))  # 32x32\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=5, strides=2, padding=\"same\"))  # 16x16\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))  # 8x8\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "    model.summary()\n",
        "    img = Input(shape=img_shape)\n",
        "    d_pred = model(img)\n",
        "    return Model(input=img, output=d_pred)\n",
        "\n",
        "def build_generator(z_dimension, channels):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128 * 8 * 8, input_dim=z_dimension))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((8, 8, 128)))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size=5, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size=5, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(32, kernel_size=5, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(channels, kernel_size=5, padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    model.summary()\n",
        "    noise = Input(shape=(z_dimension,))\n",
        "    img = model(noise)\n",
        "    return Model(input=noise, output=img)\n",
        "\n",
        "def sample_images(epoch):\n",
        "    r, c = 4, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, z_dimension))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(PATH + \"output64_cat/n_%d.png\" % epoch, dpi=200)\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCy70V0rvoW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset\n",
        "imaglist = []\n",
        "for i in range(9000):\n",
        "    imag = cv2.imread(\"out_unaug_64x64/{num}_000.jpg\".format(num=str(i).zfill(6)))\n",
        "    imag = cv2.cvtColor(imag, cv2.COLOR_BGR2RGB)\n",
        "    imaglist.append(imag)\n",
        "\n",
        "x_train = np.array(imaglist)\n",
        "x_train = x_train / 127.5 - 1.  # values -1 to 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQzZRIohvut7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "PATH = \"\"\n",
        "img_rows = 64\n",
        "img_cols = 64\n",
        "channels = 3\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "z_dimension = 64\n",
        "optimizer = Adam(0.0005, 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfJGMrpxvy4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# discriminator\n",
        "discriminator = build_discriminator(img_shape)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvj2xfxMv1AL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator\n",
        "generator = build_generator(z_dimension, channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54e7lxXtv3UE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the generator takes noise as input and generates imgs\n",
        "z = Input(shape=(z_dimension,))\n",
        "img = generator(z)\n",
        "discriminator.trainable = False\n",
        "d_pred = discriminator(img)\n",
        "# The combined model  (stacked generator and discriminator)\n",
        "combined = Model(z, d_pred)\n",
        "combined.compile(loss='binary_crossentropy',\n",
        "                 optimizer=optimizer,\n",
        "                 metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdwZP6-Hv6KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training parameters\n",
        "epochs = 10000\n",
        "batch_size = 64\n",
        "sample_interval = 100  # save some generated pictrures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v29z97QIv9a9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adversarial ground truths\n",
        "real = np.ones((batch_size, 1))\n",
        "fake = np.zeros((batch_size, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqE9GME0wAPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training\n",
        "for epoch in range(epochs):\n",
        "    print(\"epoch: \", epoch)\n",
        "    # real images\n",
        "    idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "    imgs = x_train[idx]\n",
        "    # generated images\n",
        "    noise = np.random.normal(0, 1, (batch_size, z_dimension))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    # train discriminator\n",
        "    d_loss_real = discriminator.train_on_batch(imgs, real)\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "    #d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "    # train generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, z_dimension))\n",
        "    g_loss = combined.train_on_batch(noise, real)\n",
        "    # save progress\n",
        "    if (epoch % sample_interval) == 0:\n",
        "        print(\"%d [D loss on real: %f, D loss on fake: %f, acc. on real: %.2f%%, acc. on fake: %.2f%%] [G loss: %f]\" %\n",
        "              (epoch, d_loss_real[0], d_loss_fake[0], 100 * d_loss_real[1], 100 * d_loss_fake[1], g_loss[0]))\n",
        "        sample_images(epoch)\n",
        "        generator.save(\"n_generator_64_64_z64_%d_epoch.h5\" % epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoCK8-pAwErk",
        "colab_type": "text"
      },
      "source": [
        "### Задание, поставленное в данной работе: необходимо создать модель генеративной нейронной сети для генерирования изображений котов и обучить эту модель за счет создания и обучения модели генеративно-состязательной нейронной сети (GAN)."
      ]
    }
  ]
}